{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b019b26",
   "metadata": {},
   "source": [
    "## Example  - Simple Station Distance Calculation\n",
    "\n",
    "A clean, simple example that simulates your bike rental scenario:\n",
    "- **Reader**: Loads data files and creates station lookup table\n",
    "- **Workers**: Calculate distances between stations with caching\n",
    "- **Single lock**: Simple approach for shared data access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8aac1eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "import random\n",
    "import time\n",
    "\n",
    "def data_reader(queue, lookup_table, lock, num_pairs=30, total_files=3):\n",
    "    \"\"\"Simulates loading bike rental data files\"\"\"\n",
    "    print(\"Reader: Starting...\")\n",
    "    \n",
    "    for file_num in range(1, total_files + 1):\n",
    "        print(f\"Reader: Processing file {file_num}/{total_files}\")\n",
    "        \n",
    "        # Add new stations to lookup table\n",
    "        with lock:\n",
    "            for station_id in range(1, 5 + file_num + 1):  \n",
    "                if station_id not in lookup_table:\n",
    "                    # Simulate station coordinates\n",
    "                    lookup_table[station_id] = random.uniform(10.0, 100.0)\n",
    "        \n",
    "        # Generate trip pairs (start_station, end_station)\n",
    "        for i in range(num_pairs):\n",
    "            start_station = random.randint(1, 5 + file_num)\n",
    "            end_station = random.randint(1, 5 + file_num)\n",
    "            if start_station != end_station:\n",
    "                trip_id = file_num * 1000 + i\n",
    "                queue.put((trip_id, start_station, end_station))\n",
    "            time.sleep(0.1)  # simulate file reading\n",
    "        \n",
    "        time.sleep(0.5)  # simulate file processing\n",
    "    \n",
    "    # Signal workers to stop\n",
    "    queue.put(None)\n",
    "    print(\"Reader: Finished\")\n",
    "\n",
    "def distance_worker(worker_id, queue, lookup_table, distance_cache, results, lock):\n",
    "    \"\"\"Calculates distances between stations\"\"\"\n",
    "    print(f\"Worker {worker_id}: Starting...\")\n",
    "    processed = 0\n",
    "    \n",
    "    while True:\n",
    "        item = queue.get()\n",
    "        \n",
    "        if item is None:\n",
    "            queue.put(None)  # pass shutdown signal to other workers\n",
    "            break\n",
    "        \n",
    "        trip_id, start_station, end_station = item\n",
    "        cache_key = (start_station, end_station)  # directional: (1,2) != (2,1)\n",
    "        \n",
    "        # Check cache first\n",
    "        with lock:\n",
    "            if cache_key in distance_cache:\n",
    "                distance = distance_cache[cache_key]\n",
    "                results.append((trip_id, start_station, end_station, distance, f\"Worker{worker_id}\", \"cached\"))\n",
    "                processed += 1\n",
    "                continue\n",
    "        \n",
    "        # Calculate new distance\n",
    "        with lock:\n",
    "            coord1 = lookup_table[start_station]\n",
    "            coord2 = lookup_table[end_station]\n",
    "        \n",
    "        # Simulate slow distance calculation (like OSM routing)\n",
    "        time.sleep(0.5)\n",
    "        distance = abs(coord1 - coord2)  # simple distance\n",
    "        \n",
    "        # Save to cache and results\n",
    "        with lock:\n",
    "            distance_cache[cache_key] = distance\n",
    "            results.append((trip_id, start_station, end_station, distance, f\"Worker{worker_id}\", \"calculated\"))\n",
    "        \n",
    "        processed += 1\n",
    "    \n",
    "    print(f\"Worker {worker_id}: Processed {processed} items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "899618f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 1 reader and 3 workers...\n",
      "Reader: Starting...Reader: Processing file 1/3\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker 0: Starting...\n",
      "Worker 1: Starting...Worker 2: Starting...\n",
      "\n",
      "Reader: Processing file 2/3\n",
      "Reader: Processing file 3/3\n",
      "Reader: FinishedWorker 0: Processed 19 itemsWorker 1: Processed 16 items\n",
      "Worker 2: Processed 21 items\n",
      "\n",
      "\n",
      "\n",
      "✅ Completed in 7.59 seconds\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "import threading\n",
    "import time\n",
    "\n",
    "# Setup shared data structures\n",
    "manager = mp.Manager()\n",
    "queue = manager.Queue()\n",
    "lookup_table = manager.dict()  # station_id -> coordinate\n",
    "distance_cache = manager.dict()  # (start_station, end_station) -> distance\n",
    "results = manager.list()  # trip results\n",
    "lock = manager.Lock()  # single lock for all shared data\n",
    "\n",
    "# Configuration\n",
    "num_workers = 3\n",
    "total_files = 3\n",
    "\n",
    "# Create processes\n",
    "reader_process = mp.Process(\n",
    "    target=data_reader,\n",
    "    args=(queue, lookup_table, lock, 20, total_files)\n",
    ")\n",
    "\n",
    "worker_processes = [\n",
    "    mp.Process(\n",
    "        target=distance_worker,\n",
    "        args=(i, queue, lookup_table, distance_cache, results, lock)\n",
    "    )\n",
    "    for i in range(num_workers)\n",
    "]\n",
    "\n",
    "print(f\"Starting 1 reader and {num_workers} workers...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Start all processes\n",
    "reader_process.start()\n",
    "for worker in worker_processes:\n",
    "    worker.start()\n",
    "\n",
    "# Wait for completion\n",
    "reader_process.join()\n",
    "for worker in worker_processes:\n",
    "    worker.join()\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"\\n✅ Completed in {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37559366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results Summary:\n",
      "Total trips processed: 56\n",
      "Stations in lookup table: 8\n",
      "Cached routes: 34\n",
      "Cached results: 20\n",
      "Calculated results: 36\n",
      "Cache hit rate: 35.7%\n",
      "\n",
      "🔍 Sample results (first 8):\n",
      "  🔄 Trip 1000: 6→5, Distance: 61.73, Worker0\n",
      "  🔄 Trip 1001: 6→2, Distance: 19.29, Worker2\n",
      "  🔄 Trip 1002: 2→4, Distance: 55.13, Worker1\n",
      "  🔄 Trip 1003: 6→1, Distance: 5.01, Worker0\n",
      "  🔄 Trip 1004: 2→4, Distance: 55.13, Worker2\n",
      "  🔄 Trip 1005: 2→3, Distance: 23.39, Worker1\n",
      "  💾 Trip 1006: 6→2, Distance: 19.29, Worker0\n",
      "  🔄 Trip 1007: 1→2, Distance: 24.30, Worker0\n",
      "\n",
      "👥 Work distribution:\n",
      "  Worker0: 19 trips\n",
      "  Worker1: 16 trips\n",
      "  Worker2: 21 trips\n",
      "\n",
      "🔧 Architecture:\n",
      "  ✓ Single lock for simplicity\n",
      "  ✓ Shared results list\n",
      "  ✓ Directional cache: (1,2) ≠ (2,1)\n",
      "  ✓ Queue-based work distribution\n"
     ]
    }
   ],
   "source": [
    "# Analyze results\n",
    "print(f\"\\n📊 Results Summary:\")\n",
    "print(f\"Total trips processed: {len(results)}\")\n",
    "print(f\"Stations in lookup table: {len(lookup_table)}\")\n",
    "print(f\"Cached routes: {len(distance_cache)}\")\n",
    "\n",
    "# Count cached vs calculated\n",
    "cached_count = sum(1 for r in results if r[5] == \"cached\")\n",
    "calculated_count = sum(1 for r in results if r[5] == \"calculated\")\n",
    "\n",
    "if cached_count + calculated_count > 0:\n",
    "    print(f\"Cached results: {cached_count}\")\n",
    "    print(f\"Calculated results: {calculated_count}\")\n",
    "    print(f\"Cache hit rate: {cached_count/(cached_count+calculated_count)*100:.1f}%\")\n",
    "\n",
    "# Show sample results\n",
    "print(f\"\\n🔍 Sample results (first 8):\")\n",
    "for i, result in enumerate(sorted(list(results))[:8]):\n",
    "    trip_id, start, end, dist, worker, source = result\n",
    "    status = \"💾\" if source == \"cached\" else \"🔄\"\n",
    "    print(f\"  {status} Trip {trip_id}: {start}→{end}, Distance: {dist:.2f}, {worker}\")\n",
    "\n",
    "# Worker distribution\n",
    "worker_counts = {}\n",
    "for result in results:\n",
    "    worker = result[4]\n",
    "    worker_counts[worker] = worker_counts.get(worker, 0) + 1\n",
    "\n",
    "print(f\"\\n👥 Work distribution:\")\n",
    "for worker, count in sorted(worker_counts.items()):\n",
    "    print(f\"  {worker}: {count} trips\")\n",
    "\n",
    "print(f\"\\n🔧 Architecture:\")\n",
    "print(f\"  ✓ Single lock for simplicity\")\n",
    "print(f\"  ✓ Shared results list\")\n",
    "print(f\"  ✓ Directional cache: (1,2) ≠ (2,1)\")\n",
    "print(f\"  ✓ Queue-based work distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753b6460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📍 Final Station Lookup Table:\n",
      "  Station 1: Coordinate 15.65\n",
      "  Station 2: Coordinate 39.94\n",
      "  Station 3: Coordinate 63.33\n",
      "  Station 4: Coordinate 95.07\n",
      "  Station 5: Coordinate 82.38\n",
      "  Station 6: Coordinate 20.65\n",
      "  Station 7: Coordinate 10.67\n",
      "  Station 8: Coordinate 63.43\n"
     ]
    }
   ],
   "source": [
    "for station_id, coord in sorted(lookup_table.items()):\n",
    "    print(f\"  Station {station_id}: Coordinate {coord:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745e02dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigdata_task6-3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
